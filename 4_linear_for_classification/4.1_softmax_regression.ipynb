{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Regression / exponential normalization\n",
    "\n",
    "Classification problems \n",
    "- converts K real numbers to K probabilities that sum up to 1 .. so can classify into K classes.\n",
    "- 3 classification problems - hard assignments, probabilistic assignments, and multi-assignments.\n",
    "- one-hot encoding is a vector with as many components as we have catagories, and a 1 in the position of the catagory and 0s elsewhere. eg. if dog,cat,bird the one-hot encoding would be [1,0,0], [0,1,0], [0,0,1] respectively. \n",
    "- full-connected layer: each neuron in the layer is connected to every neuron in the previous layer.\n",
    "- cross-entropy loss. measures number of bits needed to encode what we see relative to what we expected.(y and y_hat)\n",
    "\n",
    "Information theory \n",
    "- deals with problems of encoding, decoding, transmitting, and manipulating information.\n",
    "- 1 nat - 1/log(2) bits = 1.44 bits. to encode data drawn randomly from the distribution P, we need ablest H[P] nats of info.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
