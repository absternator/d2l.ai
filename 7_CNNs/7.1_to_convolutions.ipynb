{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Fully connected layers to convolutions\n",
    "- Spacial Invariance - Convolutional layers are invariant to translation. This means that the network can recognize patterns in the image no matter where they are.\n",
    "1. earliest layers network should respond to same patches regardless of where. called translation invariance.\n",
    "2. earliest layers focus on local regions of the image, called locality principle. Eventually, these can be aggregated to recognize larger patterns.\n",
    "3. deeper layers should be able to capture longer-range features in image\n",
    "\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned}$$\n",
    "\n",
    "\n",
    "- eg. using 2d inout means Hidden uses 2d as well (2d tensors). now we switch frim weight matrix to params in 4th order tensor.\n",
    "- Translation invariance - V and U does not depend on position in image. Thus, simplifying the number of parameters. as dont need i, j\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}.$$\n",
    "\n",
    "- pretty much convulutional layer above. reduced number of parameters to $4\\Delta ^ 2$ where $\\Delta$ is usually <10.\n",
    "- -ve values of a, b are used to shift the image in the opposite direction.\n",
    "- Convolutional layer - $\\mathbf{V}$ is called the convolution kernel or filter, or simply layers weights as learnable params $\\mathbf{H}$ is called the feature map.\n",
    "- Called convolution as similar as from mathematical convolution. Example using 2d: $(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).$. See very similar to the equation above. But we flip the kernel before applying it to the image. This is called cross-correlation.\n",
    "- But in images we have color channel to so need 3d tensor. So we have 3d tensor\n",
    "- Channels / feature maps - $\\mathbf{X}$ is a 3d tensor with dimensions $c \\times h \\times w$ where $c$ is the number of channels, $h$ is the height of the image, and $w$ is the width of the image. $\\mathbf{V}$ is a 3d tensor with dimensions $c \\times \\Delta \\times \\Delta$.\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},$$\n",
    "\n",
    "where d indexes output channels of **H**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
