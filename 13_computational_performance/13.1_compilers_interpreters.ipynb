{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a149553d",
   "metadata": {},
   "source": [
    "# Compilers & Interpreters\n",
    "- interpreted vs symbolic execution\n",
    "- deep learning frameworks utilise symbolic execution for optimizing performance\n",
    "- pytorch is imperative\n",
    "- torchscript\n",
    "    TorchScript code can be invoked in its own interpreter, which is basically a restricted Python interpreter. This interpreter does not acquire the Global Interpreter Lock, and so many requests can be processed on the same instance simultaneously.\n",
    "\n",
    "    This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python\n",
    "\n",
    "    TorchScript gives us a representation in which we can do compiler optimizations on the code to provide more efficient execution\n",
    "\n",
    "    TorchScript allows us to interface with many backend/device runtimes that require a broader view of the program than individual operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bba54a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "def fancy_func(a, b, c, d):\n",
      "    e = add(a, b)\n",
      "    f = add(c, d)\n",
      "    g = add(e, f)\n",
      "    return g\n",
      "print(fancy_func(1, 2, 3, 4))\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#symbolic execution\n",
    "# allows running not python env & thus avoids bottle necks from python interpreter\n",
    "# can be compiled for GPU\n",
    "def add_():\n",
    "    return '''\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "'''\n",
    "\n",
    "def fancy_func_():\n",
    "    return '''\n",
    "def fancy_func(a, b, c, d):\n",
    "    e = add(a, b)\n",
    "    f = add(c, d)\n",
    "    g = add(e, f)\n",
    "    return g\n",
    "'''\n",
    "\n",
    "def evoke_():\n",
    "    return add_() + fancy_func_() + 'print(fancy_func(1, 2, 3, 4))'\n",
    "\n",
    "prog = evoke_()\n",
    "print(prog)\n",
    "y  = compile(prog, \"\", \"exec\")\n",
    "exec(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bae1bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0010, -0.0412]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "# Factory for networks\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2))\n",
    "    return net\n",
    "\n",
    "x = torch.randn(size=(1, 512))\n",
    "net = get_net()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118b570b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0010, -0.0412]], grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.jit.script(net)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5da9b5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _0 = getattr(self, \"0\")\n",
      "  _1 = getattr(self, \"1\")\n",
      "  _2 = getattr(self, \"2\")\n",
      "  _3 = getattr(self, \"3\")\n",
      "  _4 = getattr(self, \"4\")\n",
      "  input0 = (_0).forward(input, )\n",
      "  input1 = (_1).forward(input0, )\n",
      "  input2 = (_2).forward(input1, )\n",
      "  input3 = (_3).forward(input2, )\n",
      "  return (_4).forward(input3, )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(net.code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "140a6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Benchmark:\n",
    "    \"\"\"For measuring running time.\"\"\"\n",
    "    def __init__(self, description='Done'):\n",
    "        self.description = description\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.timer = d2l.Timer()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        print(f'{self.description}: {self.timer.stop():.4f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f61bf09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without torchscript: 1.2267 sec\n",
      "With torchscript: 1.4464 sec\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "with Benchmark('Without torchscript'):\n",
    "    for i in range(10000): \n",
    "        net(x)\n",
    "    \n",
    "# will be much faster on multiple gpus\n",
    "net = torch.jit.script(net)\n",
    "with Benchmark('With torchscript'):\n",
    "    for i in range(10000): \n",
    "        net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6345ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d2215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
